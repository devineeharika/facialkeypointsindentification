{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "IMG_SIZE = 96\n",
    "data_dir = Path('./input')\n",
    "train_data = pd.read_csv(data_dir/'training.csv')\n",
    "train_data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def show_keypoints(image, keypoints):\n",
    "    \n",
    "      \n",
    "    plt.imshow(image, cmap='gray')\n",
    "    if len(keypoints):\n",
    "        plt.scatter(keypoints[:, 0], keypoints[:, 1], s=24, marker ='.', c='r')\n",
    "        \n",
    "def show_images(df, indxs, ncols=5, figsize=(15,10), with_keypoints=True):\n",
    "    plt.figure(figsize=figsize)\n",
    "    nrows = len(indxs) // ncols + 1\n",
    "    for i, idx in enumerate(indxs):\n",
    "        image = np.fromstring(df.loc[idx, 'Image'], sep=' ').astype(np.float32)\\\n",
    "                .reshape(-1, IMG_SIZE)\n",
    "        if with_keypoints:\n",
    "            keypoints = df.loc[idx].drop('Image').values.astype(np.float32)\\\n",
    "                        .reshape(-1, 2)\n",
    "        else:\n",
    "            keypoints = []\n",
    "        plt.subplot(nrows, ncols, i + 1)\n",
    "        plt.title(f'Sample #{idx}')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        show_keypoints(image, keypoints)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(train_data, range(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_data.dropna()\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(data_dir / 'test.csv')\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceKeypointsDataset(Dataset):\n",
    "\n",
    "    \n",
    "    def __init__(self, dataframe, train=True, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = np.fromstring(self.dataframe.iloc[idx, -1], sep=' ')\\\n",
    "                .astype(np.float32).reshape(-1, IMG_SIZE)\n",
    "        \n",
    "        if self.train:\n",
    "            keypoints = self.dataframe.iloc[idx, :-1].values.astype(np.float32)\n",
    "        else:\n",
    "            keypoints = None\n",
    "\n",
    "        sample = {'image': image, 'keypoints': keypoints}\n",
    "        \n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize(object):\n",
    "\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        image, keypoints = sample['image'], sample['keypoints']\n",
    "        \n",
    "        return {'image': image / 255., # scale to [0, 1]\n",
    "                'keypoints': keypoints}\n",
    "        \n",
    "class ToTensor(object):\n",
    "\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, keypoints = sample['image'], sample['keypoints']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        image = image.reshape(1, IMG_SIZE, IMG_SIZE)\n",
    "        image = torch.from_numpy(image)\n",
    "        \n",
    "        if keypoints is not None:\n",
    "            keypoints = torch.from_numpy(keypoints)\n",
    "            return {'image': image, 'keypoints': keypoints}\n",
    "        else:\n",
    "            return {'image': image}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "def prepare_train_valid_loaders(trainset, valid_size=0.2, \n",
    "                                batch_size=128):\n",
    " \n",
    "    \n",
    "    \n",
    "    num_train = len(trainset)\n",
    "    indices = list(range(num_train))\n",
    "    np.random.shuffle(indices)\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "    \n",
    "    \n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "    \n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                               sampler=train_sampler)\n",
    "    valid_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                               sampler=valid_sampler)\n",
    "    \n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df = train_data.dropna()\n",
    "test_df = test_data\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "valid_size = 0.2\n",
    "\n",
    "\n",
    "tsfm = transforms.Compose([Normalize(), ToTensor()])\n",
    "\n",
    "\n",
    "trainset = FaceKeypointsDataset(train_df, transform=tsfm)\n",
    "testset = FaceKeypointsDataset(test_df, train=False, transform=tsfm)\n",
    "\n",
    "\n",
    "train_loader, valid_loader = prepare_train_valid_loaders(trainset, \n",
    "                                                         valid_size,\n",
    "                                                         batch_size)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_layers, drop_p =0.5):\n",
    "        \n",
    "       \n",
    "        \n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        \n",
    "        layer_sizes = [(input_size, hidden_layers[0])] \\\n",
    "                      + list(zip(hidden_layers[:-1], hidden_layers[1:]))\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(h1, h2) \n",
    "                                            for h1, h2 in layer_sizes])\n",
    "        \n",
    "        self.output = nn.Linear(hidden_layers[-1], output_size)\n",
    "        \n",
    "        self.dropout = nn.Dropout(drop_p)\n",
    "        \n",
    "    def forward(self, x):\n",
    "    \n",
    "\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        for layer in self.hidden_layers:\n",
    "            x = F.relu(layer(x))\n",
    "            x = self.dropout(x)\n",
    "        x = self.output(x)    \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(input_size=IMG_SIZE*IMG_SIZE, output_size=30, \n",
    "            hidden_layers=[128, 64], drop_p=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, valid_loader, model, criterion, optimizer, \n",
    "          n_epochs=50, saved_model='model.pt'):\n",
    "    \n",
    "\n",
    "    valid_loss_min = np.Inf\n",
    "\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "    \n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        \n",
    "        model.train() \n",
    "        for batch in train_loader:\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(batch['image'].to(device))\n",
    "            \n",
    "            loss = criterion(output, batch['keypoints'].to(device))\n",
    "        \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "    \n",
    "            train_loss += loss.item()*batch['image'].size(0)\n",
    "\n",
    "        \n",
    "        model.eval()\n",
    "        for batch in valid_loader:\n",
    "        \n",
    "            output = model(batch['image'].to(device))\n",
    "\n",
    "            loss = criterion(output, batch['keypoints'].to(device))\n",
    "            \n",
    "            valid_loss += loss.item()*batch['image'].size(0)\n",
    "\n",
    "\n",
    "        train_loss = np.sqrt(train_loss/len(train_loader.sampler.indices))\n",
    "        valid_loss = np.sqrt(valid_loss/len(valid_loader.sampler.indices))\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'\n",
    "              .format(epoch+1, train_loss, valid_loss))\n",
    "\n",
    "\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'\n",
    "                  .format(valid_loss_min, valid_loss))\n",
    "            torch.save(model.state_dict(), saved_model)\n",
    "            valid_loss_min = valid_loss\n",
    "            \n",
    "    return train_losses, valid_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, valid_losses = train(train_loader, valid_loader, model,\n",
    "                                   criterion, optimizer, n_epochs=50, \n",
    "                                   saved_model='model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_RMSE(train_losses, valid_losses, y_max=50):\n",
    "    plt.plot(train_losses, \"--\", linewidth=3, label=\"train\")\n",
    "    plt.plot(valid_losses, linewidth=3, label=\"val\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.ylim((0, y_max))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_RMSE(train_losses, valid_losses, y_max=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data_loader, model):\n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data_loader):\n",
    "            output = model(batch['image'].to(device)).cpu().numpy()\n",
    "            if i == 0:\n",
    "                predictions = output\n",
    "            else:\n",
    "                predictions = np.vstack((predictions, output))\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_pred_df(columns, test_df, predictions, image_ids=range(1,6)):\n",
    "    \n",
    "    pred_df = pd.DataFrame(predictions, columns=columns)\n",
    "    pred_df = pd.concat([pred_df, test_df], axis=1)\n",
    "    pred_df = pred_df.set_index('ImageId')\n",
    "    show_images(pred_df, image_ids) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('model.pt'))\n",
    "predictions = predict(test_loader, model)\n",
    "columns = train_df.drop('Image', axis=1).columns\n",
    "view_pred_df(columns, test_df, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomHorizontalFlip(object):\n",
    "    \n",
    "    \n",
    "    def __init__(self, p=0.5):\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        \n",
    "        flip_indices = [(0, 2), (1, 3),\n",
    "                        (4, 8), (5, 9), (6, 10), (7, 11),\n",
    "                        (12, 16), (13, 17), (14, 18), (15, 19),\n",
    "                        (22, 24), (23, 25)]\n",
    "        \n",
    "        image, keypoints = sample['image'], sample['keypoints']\n",
    "        \n",
    "        if np.random.random() < self.p:\n",
    "            image = image[:, ::-1]\n",
    "            if keypoints is not None:\n",
    "                for a, b in flip_indices:\n",
    "                    keypoints[a], keypoints[b]= keypoints[b], keypoints[a]\n",
    "                keypoints[::2] = 96. - keypoints[::2]\n",
    "        \n",
    "        return {'image': image, \n",
    "                'keypoints': keypoints}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_train_df = train_data.dropna()\n",
    "aug_transform = transforms.Compose([RandomHorizontalFlip(p=1.0), \n",
    "                                    Normalize(),\n",
    "                                    ToTensor()])\n",
    "aug_trainset = FaceKeypointsDataset(aug_train_df, transform=aug_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.title(f'Original')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "image = trainset[0]['image'].numpy().squeeze()\n",
    "keypoints = trainset[0]['keypoints'].numpy().reshape(-1,2)\n",
    "show_keypoints(image, keypoints)\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(f'Horizontal Flip')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "image = aug_trainset[0]['image'].numpy().squeeze()\n",
    "keypoints = aug_trainset[0]['keypoints'].numpy().reshape(-1,2)\n",
    "show_keypoints(image, keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_dataset_images(dataset, n_images=10, n_cols=5, figsize=(15,10)):\n",
    "   \n",
    "        \n",
    "    plt.figure(figsize=figsize)\n",
    "    n_rows = n_images // n_cols + 1\n",
    "    for idx in range(n_images):\n",
    "        image = dataset[idx]['image'].numpy().squeeze()\n",
    "        keypoints = dataset[idx]['keypoints'].numpy().reshape(-1,2)\n",
    "        plt.subplot(n_rows, n_cols, idx+1)\n",
    "        plt.grid(False)\n",
    "        plt.tight_layout()\n",
    "        show_keypoints(image, keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_dataset_images(trainset, 4, 2, (6,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_dataset_images(aug_trainset, 4, 2, (6,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 128\n",
    "\n",
    "valid_size = 0.2\n",
    "\n",
    "\n",
    "\n",
    "aug_train_df = train_data.dropna()\n",
    "\n",
    "\n",
    "aug_tfms = transforms.Compose([RandomHorizontalFlip(p=0.5),\n",
    "                                    Normalize(),\n",
    "                                    ToTensor()])\n",
    "\n",
    "aug_trainset = FaceKeypointsDataset(aug_train_df, transform=aug_tfms)\n",
    "\n",
    "\n",
    "aug_train_loader, aug_valid_loader = prepare_train_valid_loaders(aug_trainset, \n",
    "                                                                 valid_size,\n",
    "                                                                 batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(input_size=IMG_SIZE*IMG_SIZE, output_size=30, hidden_layers=[128, 64], drop_p=0.1)\n",
    "model = model.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_train_losses, aug_valid_losses = train(aug_train_loader, aug_valid_loader, model, criterion, \n",
    "                                           optimizer, n_epochs=50, saved_model='aug_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_RMSE(aug_train_losses, aug_valid_losses, y_max=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('aug_model.pt'))\n",
    "predictions = predict(test_loader, model)\n",
    "columns = train_df.drop('Image', axis=1).columns\n",
    "view_pred_df(columns, test_df, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    \n",
    "    def __init__(self, outputs=30):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64*12*12, 1024)\n",
    "        self.fc2 = nn.Linear(1024, outputs)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 64*12*12)\n",
    "        x = F.relu(self.fc1(self.dropout(x)))\n",
    "        x = self.fc2(self.dropout(x))\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(outputs=30)\n",
    "model = model.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_cnn_train_losses, aug_cnn_valid_losses = train(aug_train_loader, aug_valid_loader, model, criterion, \n",
    "                                                   optimizer, n_epochs=50, saved_model='aug_cnn.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_RMSE(aug_cnn_train_losses, aug_cnn_valid_losses, y_max=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('aug_cnn.pt'))\n",
    "\n",
    "predictions = predict(test_loader, model)\n",
    "view_pred_df(columns, test_df, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {'L': ['left_eye_center_x', 'left_eye_center_y',\n",
    "                  'right_eye_center_x','right_eye_center_y',\n",
    "                  'nose_tip_x', 'nose_tip_y',\n",
    "                  'mouth_center_bottom_lip_x', 'mouth_center_bottom_lip_y',\n",
    "                  'Image'\n",
    "                 ], \n",
    "            'S': ['left_eye_inner_corner_x','left_eye_inner_corner_y', \n",
    "                  'left_eye_outer_corner_x', 'left_eye_outer_corner_y', \n",
    "                  'right_eye_inner_corner_x', 'right_eye_inner_corner_y', \n",
    "                  'right_eye_outer_corner_x', 'right_eye_outer_corner_y', \n",
    "                  'left_eyebrow_inner_end_x', 'left_eyebrow_inner_end_y', \n",
    "                  'left_eyebrow_outer_end_x', 'left_eyebrow_outer_end_y', \n",
    "                  'right_eyebrow_inner_end_x', 'right_eyebrow_inner_end_y', \n",
    "                  'right_eyebrow_outer_end_x', 'right_eyebrow_outer_end_y',\n",
    "                  'mouth_left_corner_x', 'mouth_left_corner_y', \n",
    "                  'mouth_right_corner_x', 'mouth_right_corner_y', \n",
    "                  'mouth_center_top_lip_x', 'mouth_center_top_lip_y',\n",
    "                  'Image'\n",
    "                 ]\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomHorizontalFlip(object):\n",
    "    \n",
    "    \n",
    "    def __init__(self, p=0.5, dataset='A'):\n",
    "        \n",
    "        \n",
    "        self.p = p\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        \n",
    "        if self.dataset == 'L':\n",
    "            flip_indices = [(0, 2), (1, 3)]\n",
    "        elif self.dataset == 'S':\n",
    "            flip_indices = [(0, 4), (1, 5), (2, 6), (3, 7),\n",
    "                            (8, 12), (9, 13), (10, 14), (11, 15),\n",
    "                            (16, 18), (17, 19)]\n",
    "        else:\n",
    "            flip_indices = [(0, 2), (1, 3),\n",
    "                            (4, 8), (5, 9), (6, 10), (7, 11),\n",
    "                            (12, 16), (13, 17), (14, 18), (15, 19),\n",
    "                            (22, 24), (23, 25)]\n",
    "        \n",
    "        image, keypoints = sample['image'], sample['keypoints']\n",
    "        \n",
    "        if np.random.random() < self.p:\n",
    "            image = image[:, ::-1]\n",
    "            if keypoints is not None:\n",
    "                for a, b in flip_indices:\n",
    "                    keypoints[a], keypoints[b]= keypoints[b], keypoints[a]\n",
    "                keypoints[::2] = 96. - keypoints[::2]\n",
    "        \n",
    "        return {'image': image, \n",
    "                'keypoints': keypoints}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_aug_df = train_data[datasets['L']].dropna()\n",
    "\n",
    "L_aug_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "L_aug_tfms = transforms.Compose([RandomHorizontalFlip(p=0.5, dataset='L'),\n",
    "                                 Normalize(), ToTensor()])\n",
    "\n",
    "\n",
    "L_aug_trainset = FaceKeypointsDataset(L_aug_df, transform=L_aug_tfms)\n",
    "\n",
    "\n",
    "\n",
    "L_aug_train_loader, L_aug_valid_loader = prepare_train_valid_loaders(L_aug_trainset, \n",
    "                                                                     valid_size,\n",
    "                                                                     batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = len(datasets['L']) - 1\n",
    "model = CNN(outputs)\n",
    "model = model.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_train_losses, L_valid_losses = train(L_aug_train_loader, L_aug_valid_loader, \n",
    "                                   model, criterion, optimizer, \n",
    "                                   n_epochs=50, saved_model='L_aug_cnn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_RMSE(L_train_losses, L_valid_losses, y_max=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('L_aug_cnn.pt'))\n",
    "\n",
    "L_predictions = predict(test_loader, model)\n",
    "\n",
    "L_columns = L_aug_df.drop('Image', axis=1).columns\n",
    "\n",
    "view_pred_df(L_columns, test_df, L_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_aug_df = train_data[datasets['S']].dropna()\n",
    "S_aug_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "S_aug_tfms = transforms.Compose([RandomHorizontalFlip(p=0.5, dataset='S'),\n",
    "                                 Normalize(), ToTensor()])\n",
    "\n",
    "S_aug_trainset = FaceKeypointsDataset(S_aug_df, transform=S_aug_tfms)\n",
    "\n",
    "\n",
    "\n",
    "S_aug_train_loader, S_aug_valid_loader = prepare_train_valid_loaders(S_aug_trainset, \n",
    "                                                                     valid_size,\n",
    "                                                                     batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = len(datasets['S']) - 1\n",
    "model = CNN(outputs)\n",
    "model = model.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_train_losses, S_valid_losses = train(S_aug_train_loader, S_aug_valid_loader, \n",
    "                                   model, criterion, optimizer, \n",
    "                                   n_epochs=50, saved_model='S_aug_cnn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_RMSE(S_train_losses, S_valid_losses, y_max= 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('S_aug_cnn.pt'))\n",
    "\n",
    "S_predictions = predict(test_loader, model)\n",
    "\n",
    "S_columns = S_aug_df.drop('Image', axis=1).columns\n",
    "\n",
    "view_pred_df(S_columns, test_df, S_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.hstack((L_predictions, S_predictions))\n",
    "columns = list(L_columns) + list(S_columns)\n",
    "view_pred_df(columns, test_df, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
